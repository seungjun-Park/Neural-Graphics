module:
  target: models.classification.EIPS
  params:
    # ckpt_path: './checkpoints/eips/arknights100_best.ckpt'
    margin: 0.2
    lr: 2e-5
    weight_decay: 0.
    net_config:
      in_channels: 3
      in_res: 512
      window_size: 8
      patch_size: 2
      hidden_dims: [ 64, 128, 128, 256, 256 ]
      embed_dim: 32
      num_blocks: 2
      num_groups: 32
      num_heads: [ 4, 8, 8, 16, 16 ]
      dropout: 0.0
      attn_dropout: 0.0
      drop_path: 0.1
      qkv_bias: True
      bias: True
      act: 'gelu'
      use_conv: True
      pool_type: 'avg'
      dim: 2
      use_checkpoint: True
      attn_mode: 'cosine'
      use_norm: True

    criterion_config:
      target: utils.loss.CosineSimilarity
      params:
        cd_dim: 1
        reduction: 'mean'

data:
  target: modules.datasets.util.DataModuleFromConfig
  params:
    num_workers: 4
    batch_size: 2
    wrap: True
    train:
      target: modules.datasets.arknights.ArknightsImageEdgeSimilarity
      params:
        root: '/local_datasets/arknights100'
        train: True
        size: 512
        scale: [0.7, 1.0]
        ratio: [1.0, 1.0]
        color_space: 'rgb'

    validation:
      target: modules.datasets.arknights.ArknightsImageEdgeSimilarity
      params:
        root: '/local_datasets/arknights100'
        train: False
        size: 512
        scale: [ 0.7, 1.0 ]
        ratio: [ 1.0, 1.0 ]
        color_space: 'rgb'


logger:
  target: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
  params:
    save_dir: './logs'
    name: 'eips'
    version: 'arknights100'


checkpoints:
  latest_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/eips/'
      filename: 'arknights100'
      monitor: 'step'
      mode: 'max'
      save_top_k: 1

  best_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/eips/'
      filename: 'arknights100_best'
      monitor: 'val/loss'
      mode: 'min'
      save_top_k: 1

trainer:
  accelerator: 'gpu'
  max_epochs: 1000
  accumulate_grad_batches: 5