module:
  target: models.classification.SwinTransformer
  params:
    in_channels: 3
    in_res: 512
    window_size: 8
    patch_size: 2
    hidden_dims: [64, 128, 256, 512]
    embed_dim: 32
    quant_dim: 4
    logit_dim: 20
    num_blocks: [1, 1, 3, 1]
    num_groups: 32
    num_heads: 8
    dropout: 0.1
    attn_dropout: 0.1
    drop_path: 0.0
    qkv_bias: True
    bias: True
    act: 'gelu'
    use_conv: True
    pool_type: 'conv'
    dim: 2
    use_checkpoint: True
    attn_mode: 'cosine'
    use_norm: True
    lr: 2e-5
    weight_decay: 0.
    # ckpt_path: './checkpoints/classification/arknights100.ckpt'

data:
  target: modules.datasets.util.DataModuleFromConfig
  params:
    num_workers: 4
    batch_size: 2
    wrap: True
    train:
      target: modules.datasets.arknights.ArknightsEdgeClassification
      params:
        root: '/local_datasets/arknights100'
        train: True
        size: 512
        scale: [0.9, 1.0]
        ratio: [1.0, 1.0]
        color_space: 'rgb'

#    validation:
#      target: modules.datasets.arknights.ArknightsEdgeClassification
#      params:
#        root: '/local_datasets/arknights100'
#        train: False
#        size: 512
#        scale: [ 0.9, 1.0 ]
#        ratio: [ 1.0, 1.0 ]
#        color_space: 'rgb'


logger:
  target: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
  params:
    save_dir: './logs'
    name: 'classification'
    version: 'arknights100'


checkpoints:
  latest_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/classification/'
      filename: 'arknights100'
      monitor: 'step'
      mode: 'max'
      save_top_k: 1

#  best_checkpoint:
#    target: pytorch_lightning.callbacks.ModelCheckpoint
#    params:
#      dirpath: './checkpoints/classification/'
#      filename: 'arknights100_best'
#      monitor: 'val/loss'
#      mode: 'min'
#      save_top_k: 1

trainer:
  accelerator: 'gpu'
  max_epochs: 200
  accumulate_grad_batches: 5