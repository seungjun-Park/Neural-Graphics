module:
  target: models.vae.autoencoder.ComplexAutoencoderKL
  params:
    dim: 2
    lr: 1e-4
    weight_decay: 0.
    log_interval: 1000

    enc_dec_config:
      in_channels: 3
      hidden_dims: [128, 256, 512, 512]
      embed_dim: 64
      z_channels: 4
      latent_dim: 4
      num_res_blocks: 2
      attn_res: []
      num_heads: -1
      num_head_channels: 32
      dropout: 0.0
      attn_dropout: 0.0
      use_bias: True
      num_groups: 32
      act: 'gelu'
      dim: 2
      mode: 'nearest'
      attn_type: 'fft'

    loss_config:
      target: modules.loss.contperceptual.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        logvar_init: 0.0
        kl_weight: 0
        pixelloss_weight: 1.0
        disc_num_layers: 3
        disc_in_channels: 3
        disc_factor: 1.0
        disc_weight: 1.0
        perceptual_weight: 1.0
        use_actnorm: False
        disc_conditional: False
        disc_loss: "hinge"

        lpips_config:
          ckpt_path: 'checkpoints/lpips/swin_v2_t/lpips.ckpt'
          net_type: 'swin_v2_t'

data:
  target: modules.datasets.util.DataModuleFromConfig
  params:
    num_workers: 2
    batch_size: 1
    wrap: True
    train:
      target: modules.datasets.genshin_impact.GenshinImpactDataset
      params:
        root: '/local_datasets/genshin_impact'
        train: True
        transform_configs:
          transforms:
            - target: torchvision.transforms.transforms.ToTensor
            - target: torchvision.transforms.transforms.Resize
              params:
                size: [ 512, 512 ]
    validation:
      target: modules.datasets.genshin_impact.GenshinImpactDataset
      params:
        root: '/local_datasets/genshin_impact'
        train: False
        transform_configs:
          transforms:
            - target: torchvision.transforms.transforms.ToTensor
            - target: torchvision.transforms.transforms.Resize
              params:
                size: [ 512, 512 ]


logger:
  target: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
  params:
    save_dir: './logs'
    name: 'autoencoder'
    version: 'complex'


checkpoints:
  best_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/autoencoder/complex'
      filename: 'autoencoder'
      monitor: 'val/rec_loss'
      mode: 'min'
      save_top_k: 1

trainer:
  accelerator: 'gpu'
  max_epochs: 5