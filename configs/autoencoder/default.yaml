module:
  target: models.vae.autoencoder.AutoencoderKL
  params:
    encoder_low_config:
      target: modules.vae.encoder.Encoder
      params:
        in_channels: 3
        embed_dim: 64
        hidden_dims: [ 128, 256, 512, 512 ]
        num_res_blocks: 2
        dropout: 0.1
        dim: 2
        act: 'gelu'
    encoder_high_config:
      target: modules.vae.encoder.Encoder
      params:
        in_channels: 3
        embed_dim: 64
        hidden_dims: [ 128, 256, 512, 512 ]
        num_res_blocks: 2
        dropout: 0.1
        dim: 2
        act: 'gelu'
    middle_block_config:
      target: modules.vae.middle_block.MiddleBlock
      params:
        in_channels: 1024
        out_channels: 4  # same as z_channels
        num_attn_blocks: 2
        num_head_channels: 32
        dropout: 0.1
        attn_dropout: 0.1
        dim: 2
        act: 'gelu'

    decoder_config:
      target: modules.vae.decoder.Decoder
      params:
        in_channels: 4 # same as z_channels
        out_channels: 3
        embed_dim: 64
        hidden_dims: [ 128, 256, 512, 512 ]
        num_res_blocks: 2
        dropout: 0.1
        dim: 2
        act: 'gelu'

    z_channels: 4
    latent_dim: 4
    dim: 2
    lr: 2e-5
    weight_decay: 0.
    log_interval: 1000
    loss_config:
      target: modules.loss.contperceptual.LPIPSWithDiscriminator
      params:
        lpips_config:
          net_type: 'swin_v2_t'
          ckpt_path: 'checkpoints/lpips/swin_v2_t/lpips.ckpt'
        disc_start: 0
        logvar_init: 0.0
        kl_weight: 1e-5
        pixelloss_weight: 1.0
        disc_num_layers: 3
        disc_in_channels: 3
        disc_factor: 1.0
        disc_weight: 1.0
        perceptual_weight: 1.0
        use_actnorm: False
        disc_conditional: False
        disc_loss: "hinge"

data:
  target: modules.datasets.util.DataModuleFromConfig
  params:
    num_workers: 2
    batch_size: 1
    wrap: True
    train:
      target: modules.datasets.genshin_impact.GenshinImpactDataset
      params:
        root: '/local_datasets/genshin_impact'
        train: True
        bandwidth: 0.3
        transform_configs:
          transforms:
            - target: torchvision.transforms.transforms.ToTensor
            - target: torchvision.transforms.transforms.Resize
              params:
                size: [ 512, 512 ]
    validation:
      target: modules.datasets.genshin_impact.GenshinImpactDataset
      params:
        root: '/local_datasets/genshin_impact'
        train: False
        bandwidth: 0.3
        transform_configs:
          transforms:
            - target: torchvision.transforms.transforms.ToTensor
            - target: torchvision.transforms.transforms.Resize
              params:
                size: [ 512, 512 ]


logger:
  target: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
  params:
    save_dir: './logs'
    name: 'autoencoder'
    version: 'default'


checkpoints:
  latest_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/autoencoder/default'
      filename: 'autoencoder'
      monitor: 'step'
      mode: 'max'
      save_top_k: 1

  best_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/autoencoder/default'
      filename: 'autoencoder_best'
      monitor: 'val/rec_loss'
      mode: 'min'
      save_top_k: 1

trainer:
  accelerator: 'gpu'
  max_epochs: 10